{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,average_precision_score,recall_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('Dataset_2738_after_webscraping.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "C = (df['Content']).tolist()\n",
    "\n",
    "L = (df['Label']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING\n",
    "def preprocess(col):\n",
    "    col_l = []\n",
    "    for r in col:\n",
    "        #print(r)\n",
    "        try:\n",
    "            a = r.lower() \n",
    "            a = a.replace(\"'s\", \"\")\n",
    "            #a = a.replace([\"\\n\"], \"hjfgjh\")\n",
    "            a = re.sub('[^a-zA-Z0-9 \\n\\.]', '',a)\n",
    "            a = re.sub('[:.\\n\\t]', '',a)\n",
    "            a = re.sub('[?:!.+,]]][]]//;]', '',a) \n",
    "            \n",
    "            col_l.append(a)\n",
    "        except:\n",
    "            #print(\"No header found\")\n",
    "            col_l.append(\"No Header\")\n",
    "            pass\n",
    "\n",
    "    # Downloading punkt and wordnet from NLTK\n",
    "    nltk.download('punkt')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    nltk.download('wordnet')\n",
    "    \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    lemmatized_text_list = []\n",
    "\n",
    "    for s in col_l:\n",
    "        #print(s)\n",
    "        # Create an empty list containing lemmatized words\n",
    "        lemmatized_list = []\n",
    "\n",
    "        # Save the text and its words into an object\n",
    "        #text = df.loc[row]['Content_Parsed_4']\n",
    "        text_words = s.split(\" \")\n",
    "\n",
    "        # Iterate through every word to lemmatize\n",
    "        for word in text_words:\n",
    "            lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "\n",
    "        # Join the list\n",
    "        lemmatized_text = \" \".join(lemmatized_list)\n",
    "\n",
    "        # Append to the list containing the texts\n",
    "        lemmatized_text_list.append(lemmatized_text)\n",
    "    \n",
    "    new_lemmatized_text_list = []\n",
    "    for x in lemmatized_text_list:\n",
    "        new_lemmatized_text_list.append(\" \".join(x.split())) \n",
    "    \n",
    "    pl = pd.Series(new_lemmatized_text_list)\n",
    "   # pl = pd.Series(col_l)\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    \n",
    "    for stop_word in stop_words:\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        #pl = pd.Series(col_l)\n",
    "   \n",
    "        pl = pl.str.replace(regex_stopword, '')\n",
    "        \n",
    "    \n",
    "    return pl.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jojy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jojy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jojy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "con = preprocess(C)\n",
    "#print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2734"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " 'iot-project',\n",
       " ...]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in L:\n",
    "    if i == 'iot-project' or i == 'Iot-Project':\n",
    "        label.append(1)\n",
    "        \n",
    "    elif i == 'non-iot-project':\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2734"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {'non-iot-project': 0, 'iot-project': 1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'non-iot-project': 0, 'iot-project': 1}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "la2 = pd.Series(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_2 = la2.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "2729    0\n",
       "2730    0\n",
       "2731    0\n",
       "2732    0\n",
       "2733    0\n",
       "Length: 2734, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2734"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(la_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.DataFrame({\"Content\":con})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connect  modbus energy meter   arduino  monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>remote control  laser   use  multiple argons r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know   go check   trek get call without stall ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simple tutorial  connect microbit  azure  les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tire  joystick control   phone use l298n ardui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>traditional saffron buns lussekatter  swedish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>camera bag   useful  carry   stuff   trip    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>various reason  wont bore    spend  little ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>ahoy mateys fancy  cold drink   treasure chest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>one   many fashion trend   last two years   ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2734 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content\n",
       "0     connect  modbus energy meter   arduino  monito...\n",
       "1     remote control  laser   use  multiple argons r...\n",
       "2     know   go check   trek get call without stall ...\n",
       "3      simple tutorial  connect microbit  azure  les...\n",
       "4     tire  joystick control   phone use l298n ardui...\n",
       "...                                                 ...\n",
       "2729  traditional saffron buns lussekatter  swedish ...\n",
       "2730   camera bag   useful  carry   stuff   trip    ...\n",
       "2731   various reason  wont bore    spend  little ti...\n",
       "2732  ahoy mateys fancy  cold drink   treasure chest...\n",
       "2733  one   many fashion trend   last two years   ri...\n",
       "\n",
       "[2734 rows x 1 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################  Training Module Starts  #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, la_2, test_size=0.15, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>project   learn   make  diy smart smoke dete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>system  early detection  gas  home  activation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>instructable  show   make  dry chilli flake ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>get  enviromental data  around  machine    see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>fish tank   mini waterfallit   keep indoor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>stick  home away   love one  fun little projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>tutorial   cover make  security motion detec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>riot lorawan sensors communicate   things netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>automate entryexit use rfid  mysql database re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>crave  reuben  look   delicious rye bread  imp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content\n",
       "1214    project   learn   make  diy smart smoke dete...\n",
       "271   system  early detection  gas  home  activation...\n",
       "1798    instructable  show   make  dry chilli flake ...\n",
       "663   get  enviromental data  around  machine    see...\n",
       "1926     fish tank   mini waterfallit   keep indoor ...\n",
       "...                                                 ...\n",
       "636   stick  home away   love one  fun little projec...\n",
       "1331    tutorial   cover make  security motion detec...\n",
       "392   riot lorawan sensors communicate   things netw...\n",
       "995   automate entryexit use rfid  mysql database re...\n",
       "2617  crave  reuben  look   delicious rye bread  imp...\n",
       "\n",
       "[411 rows x 1 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2489    0\n",
       "184     1\n",
       "1360    1\n",
       "212     1\n",
       "186     1\n",
       "       ..\n",
       "2181    0\n",
       "2409    0\n",
       "2033    0\n",
       "1364    1\n",
       "451     1\n",
       "Length: 2323, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features =300# not clear how to choose this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.0808623  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.12261781 0.13333277 0.         ... 0.         0.         0.        ]\n",
      " [0.12670741 0.08137494 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.10952727 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "features_train = tfidf.fit_transform(X_train['Content']).toarray()\n",
    "print(features_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.16302062 0.08384268]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.16349116 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.35320005 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "features_test = tfidf.fit_transform(X_test['Content']).toarray()\n",
    "print(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#####################################  Training Module Ends  #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## DECISION TREE ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=20, splitter='best')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DTC =DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,max_features=None, max_leaf_nodes=10, min_samples_leaf=5,min_samples_split=2, min_weight_fraction_leaf=0.0,random_state=None, splitter='random')\n",
    "DTC = DecisionTreeClassifier(random_state=20)\n",
    "DTC.fit(features_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(DTC, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuacy 1.0\n",
      "Testing Accuacy 0.9951338199513382\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result1 = loaded_model.score(features_train, y_train)\n",
    "result = loaded_model.score(features_test, y_test)\n",
    "\n",
    "print(\"Training Accuacy\",result1)\n",
    "print(\"Testing Accuacy\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DTC_pred = loaded_model.predict(features_test)\n",
    "DTC_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[199   2]\n",
      " [  0 210]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, DTC_pred)\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       201\n",
      "           1       0.99      1.00      1.00       210\n",
      "\n",
      "    accuracy                           1.00       411\n",
      "   macro avg       1.00      1.00      1.00       411\n",
      "weighted avg       1.00      1.00      1.00       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, DTC_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############NAIVE BAYES######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(features_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename_naive = 'finalized_naive.sav'\n",
    "pickle.dump(Naive, open(filename_naive, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuacy 0.995264743865691\n",
      "Testing Accuacy 0.9440389294403893\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_naive = pickle.load(open(filename_naive, 'rb'))\n",
    "result = loaded_naive.score(features_train, y_train)\n",
    "result1 = loaded_naive.score(features_test, y_test)\n",
    "print(\"Training Accuacy\",result)\n",
    "print(\"Testing Accuacy\",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Naive_pred = loaded_naive.predict(features_test)\n",
    "Naive_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[198   3]\n",
      " [ 20 190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       201\n",
      "           1       0.98      0.90      0.94       210\n",
      "\n",
      "    accuracy                           0.94       411\n",
      "   macro avg       0.95      0.94      0.94       411\n",
      "weighted avg       0.95      0.94      0.94       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, Naive_pred)\n",
    "print(matrix)\n",
    "report = classification_report(y_test, Naive_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = svm.LinearSVC(C=0.1)\n",
    "SVM.fit(features_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename_svm = 'finalized_svm.sav'\n",
    "pickle.dump(SVM, open(filename_svm, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuacy 0.9987085665088248\n",
      "Testing Accuacy 0.9391727493917275\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_svm = pickle.load(open(filename_svm, 'rb'))\n",
    "result = loaded_svm.score(features_train, y_train)\n",
    "result1 = loaded_svm.score(features_test, y_test)\n",
    "print(\"Training Accuacy\",result)\n",
    "print(\"Testing Accuacy\",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pred = loaded_svm.predict(features_test)\n",
    "svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  14]\n",
      " [ 11 199]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       201\n",
      "           1       0.93      0.95      0.94       210\n",
      "\n",
      "    accuracy                           0.94       411\n",
      "   macro avg       0.94      0.94      0.94       411\n",
      "weighted avg       0.94      0.94      0.94       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, svm_pred)\n",
    "print(matrix)\n",
    "report = classification_report(y_test, svm_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
    "knn.fit(features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename_knn = 'finalized_knn.sav'\n",
    "pickle.dump(knn, open(filename_knn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  Accuacy 1.0\n",
      "Testing Accuacy 0.9148418491484185\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_knn = pickle.load(open(filename_knn, 'rb'))\n",
    "result = loaded_knn.score(features_train, y_train)\n",
    "result1= loaded_knn.score(features_test, y_test)\n",
    "print(\"Training  Accuacy\",result)\n",
    "print(\"Testing Accuacy\",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred = loaded_knn.predict(features_test)\n",
    "knn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191  10]\n",
      " [ 25 185]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92       201\n",
      "           1       0.95      0.88      0.91       210\n",
      "\n",
      "    accuracy                           0.91       411\n",
      "   macro avg       0.92      0.92      0.91       411\n",
      "weighted avg       0.92      0.91      0.91       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, knn_pred)\n",
    "print(matrix)\n",
    "report = classification_report(y_test, knn_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=8, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=100)\n",
    "SGD = SGDClassifier(random_state=8)\n",
    "SGD.fit(features_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename_sgd = 'finalized_sgd.sav'\n",
    "pickle.dump(SGD, open(filename_sgd, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuacy 1.0\n",
      "Testing Accuacy 0.8880778588807786\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_sgd = pickle.load(open(filename_sgd, 'rb'))\n",
    "result1 = loaded_sgd.score(features_train, y_train)\n",
    "result = loaded_sgd.score(features_test, y_test)\n",
    "print(\"Training Accuacy\",result1)\n",
    "print(\"Testing Accuacy\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_pred = loaded_sgd.predict(features_test)\n",
    "sgd_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[162  39]\n",
      " [  7 203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88       201\n",
      "           1       0.84      0.97      0.90       210\n",
      "\n",
      "    accuracy                           0.89       411\n",
      "   macro avg       0.90      0.89      0.89       411\n",
      "weighted avg       0.90      0.89      0.89       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, sgd_pred)\n",
    "print(matrix)\n",
    "report = classification_report(y_test, sgd_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='log2',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=2,\n",
       "                       n_jobs=None, oob_score=False, random_state=47, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "random = RandomForestClassifier(n_estimators=2,max_features='log2',random_state=47)\n",
    "#regressor = RandomForestRegressor(n_estimators=2, max_depth=None,min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None,bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "random.fit(features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename_random = 'finalized_random.sav'\n",
    "pickle.dump(random, open(filename_random, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuacy 0.998278088678433\n",
      "Testing Accuacy 0.9197080291970803\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_random = pickle.load(open(filename_random, 'rb'))\n",
    "result1 = loaded_random.score(features_train, y_train)\n",
    "result = loaded_random.score(features_test, y_test)\n",
    "print(\"Training Accuacy\",result1)\n",
    "print(\"Testing Accuacy\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pred = loaded_random.predict(features_test)\n",
    "random_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[162  39]\n",
      " [  7 203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88       201\n",
      "           1       0.84      0.97      0.90       210\n",
      "\n",
      "    accuracy                           0.89       411\n",
      "   macro avg       0.90      0.89      0.89       411\n",
      "weighted avg       0.90      0.89      0.89       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, sgd_pred)\n",
    "print(matrix)\n",
    "report = classification_report(y_test, sgd_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
